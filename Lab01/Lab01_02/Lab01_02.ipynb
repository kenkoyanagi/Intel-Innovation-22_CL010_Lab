{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783b6cef",
   "metadata": {},
   "source": [
    "## Lab01_02: Using IntelÂ® Neural Compressor to quantize a model\n",
    "\n",
    "### Prerequisites: \n",
    "- onnx\n",
    "- onnxruntime \n",
    "- onnxruntime-extensions\n",
    "- neural_compressor \n",
    "- numpy \n",
    "\n",
    "### Objective:\n",
    "- Learn the basics of the quantization pipeline (API, dataset, configuration file, quantization type)\n",
    "- Evaluate the accuracy difference between dynamic quantization and accuracy aware quantization \n",
    "- Quantize ResNet50 exported from Lab01_01 to produce quantized Int8 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "from neural_compressor.experimental import Quantization, common\n",
    "from neural_compressor import options\n",
    "\n",
    "options.onnxrt.graph_optimization.level = 'ENABLE_BASIC'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de6eb4",
   "metadata": {},
   "source": [
    "Load the previously generated Float32 ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9588211",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(\"../../models/resnet50.onnx\")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c720c",
   "metadata": {},
   "source": [
    "Here, we'll try two common types of quantization schemes:\n",
    "- Dynamic Quantization, which does not require a dataset, and therefore less code/configuration\n",
    "- Accuracy Aware Quantization, which DOES require a dataset, but typically results in better accuracy\n",
    "\n",
    ">Load each configuration 'yaml' files and run the quantization function. Compare both results. \\\n",
    "    - Dynamic Quantization = **resnet50_v1_5_dynamicq.yaml** \\\n",
    "    - Accuracy Aware Quantization = **resnet50_v1_5_qdq.yaml** \\\n",
    "    - The dataset and label file can be located in the resources/ folder \\\n",
    "    - Make the changes in **resnet50_v1_5_qdq.yaml** to reference the filepath to both the dataset folder and the label file\n",
    "\n",
    "> Dynamic Quantization does not require a sample dataset and label file for calibration, but we are referencing it for evaluating how well the quantization scheme performed. \n",
    "\n",
    ">Static Quantization method will require a sample dataset and label file for calibrating the model. \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize = Quantization('''TODO: Try both configuration files for quantization options''') # Configuration .yaml file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e753f",
   "metadata": {},
   "source": [
    ">Quantize the model and save it to the models folder\n",
    "\n",
    ">Use the [quantize() and save()](https://github.com/intel/neural-compressor/tree/master/examples/tensorflow/image_recognition/tensorflow_models/quantization/ptq#code-update) APIs\n",
    "\n",
    "Refer to the slidedeck for additional help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa5498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    TODO: Run the quantization API (quantize()) to generate the quantized model\n",
    "'''\n",
    "\n",
    "# Save the quantized model under the models/ folder\n",
    "q_model.save(\"../../models/resnet50_int8.onnx\")\n",
    "print(\"Int8 Quantized model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
