{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d63abf",
   "metadata": {},
   "source": [
    "## Lab03_01: Style Transfer with ONNXRuntime and Microsoft DirectML \n",
    "\n",
    "### Prerequisites: \n",
    "- onnx\n",
    "- onnxruntime\n",
    "- numpy\n",
    "- cv\n",
    "- pytorch (tortch)\n",
    "\n",
    "### Objective:\n",
    "- Learn to use ONNXRuntime + DirectML by using the Style Transfer model from Lab01. \n",
    "\n",
    "\n",
    "We'll be using a Mosaic model which comes from the ONNX Model Repository. It's based off the research paper *Perceptual Losses for Real-Time Style Transfer and Super-Resolution* by Justin Johnson, Alexandre Alahi, and Li Fei-Fei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnxruntime\n",
    "!pip install onnxruntime-directml\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from onnx import numpy_helper\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from onnx.tools import update_model_dims\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412a9d1",
   "metadata": {},
   "source": [
    "Let's begin by loading the model from Lab01_03. \n",
    "\n",
    "Remember, we want to use Float16 models on GPU for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dce94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and verify model\n",
    "model_name = '../../models/style-transfer-fp16.onnx'    #Model generated from Lab01_03 \n",
    "onnx_model = onnx.load(model_name)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"Model loaded and verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ed718",
   "metadata": {},
   "source": [
    ">Find DirectML (DML) through the available providers and select that for our session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find available providers and create the Inference session targeted for GPU\n",
    "print(\"Available providers\")\n",
    "'''\n",
    "    TODO: Print out all of the available execution providers on the system\n",
    "\n",
    "'''\n",
    "\n",
    "start_session = time.time() # Excerise - Create the inference n DirectML device\n",
    "'''\n",
    "    TODO: Set the execution provider as DirectML\n",
    "'''\n",
    "elapsed_time_session_creation = ((time.time() - start_session)*1000)\n",
    "\n",
    "#Print the session creation time\n",
    "print(f\"Session Creation time (msec) : {elapsed_time_session_creation:0.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b7aed",
   "metadata": {},
   "source": [
    "Let's take a look at the model to understand the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1177f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = session.get_inputs()[0].name\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "input_type = session.get_inputs()[0].type\n",
    "\n",
    "print(\"input name\", input_name)\n",
    "print(\"input shape\", input_shape)\n",
    "print(\"input type\", input_type)\n",
    "\n",
    "outname = [output.name for output in session.get_outputs()]\n",
    "print(\"outputs\", outname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857cda44",
   "metadata": {},
   "source": [
    "Load in a sample image and go through the pre-processing steps. \n",
    ">Read in the sample image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread(\"../../resources/lab03_image.jpg\")\n",
    "# Convert to RGB\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# Resize the image to 224x224,3\n",
    "img = cv2.resize(img,(224,224),interpolation = cv2.INTER_LANCZOS4)\n",
    "image = np.array(img, dtype=np.float16)\n",
    "image = image.transpose((2,0,1))[np.newaxis, ...]\n",
    "plt.imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c26ee",
   "metadata": {},
   "source": [
    "Run inference on the sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ortvalue can be provided as part of the input feed to a model\n",
    "data_output = session.run(outname, {input_name: image})[0][0] \n",
    "\n",
    "# Single output output \n",
    "output = data_output[0]\n",
    "result = np.clip(data_output, 0, 255)\n",
    "result = result.transpose(1,2,0).astype(\"uint8\")\n",
    "# Show and save the output\n",
    "plt.imshow(np.asarray(result))\n",
    "cv2.imwrite(\"../../resources/Lab03_01_output.png\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc5f9b",
   "metadata": {},
   "source": [
    "Let's now evaluate our baseline performance by running inference 1000 times\n",
    "\n",
    "> Complete the run call with the style transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db25493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating for Performance\\n\")\n",
    "start_perf_base = time.time()\n",
    "for i in range(100):\n",
    "    data_output = session.run(outname, {input_name: image})[0][0] # Run inference here by completing the run() call\n",
    "# Print the average time\n",
    "elapsed_time_baseline_perf = ((time.time() - start_perf_base)*1000)/100\n",
    "print(f\"Average inference time (msec) : {elapsed_time_baseline_perf:0.3f}\\n\")\n",
    "del session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba199ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and verify model\n",
    "model_name = '../../models/style-transfer=fp16-fixed.onnx' # Model generated from Lab01_03 \n",
    "onnx_model = onnx.load(model_name)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"Model loaded and verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89891521",
   "metadata": {},
   "source": [
    "Let's reduce the session creation time\n",
    "> Disable memory pattern, disable graph optimizations, and fix the input shapes using the denotation API\n",
    "\n",
    "Then observe the difference in session creation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the session options by creation SessionOptions() object below\n",
    "'''\n",
    "    TODO: Disable memory patterns, disable graph optimizations, \n",
    "        and override the \"free\" dimensions using the denotation() API to set the batch size to 1\n",
    "'''\n",
    "\n",
    "#Create the inference session\n",
    "start = time.time() \n",
    "'''\n",
    "    TODO: Create the inference session with DirectML\n",
    "'''\n",
    "elapsed_time = ((time.time() - start)*1000)\n",
    "print(f\"Session Creation time (msec) : {elapsed_time:0.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = session.get_inputs()[0].name\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "input_type = session.get_inputs()[0].type\n",
    "\n",
    "print(\"input name\", input_name)\n",
    "print(\"input shape\", input_shape)\n",
    "print(\"input type\", input_type)\n",
    "\n",
    "outname = [output.name for output in session.get_outputs()]\n",
    "print(\"outputs\", outname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f286a16",
   "metadata": {},
   "source": [
    "Let's also evaluate the performance for n number of inference runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating for Performance\\n\")\n",
    "t_start = time.time()\n",
    "for i in range(100):\n",
    "    data_output = session.run(outname, {input_name: image})[0][0] # Run inference here by completing the run() call\n",
    "# Print the average time\n",
    "elapsed_time_optimized_perf = ((time.time() - t_start)*1000)/100\n",
    "print(f\"Average inference time (msec) : {elapsed_time_optimized_perf:0.3f}\\n\")\n",
    "del session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = [[\"Baseline Session Creation\",elapsed_time_session_creation],\n",
    "          [\"Optimize Session Creation\",elapsed_time],\n",
    "          [\"Avg Inference Time Baseline\",elapsed_time_baseline_perf],\n",
    "          [\"Avg Inference Time optimized\",elapsed_time_optimized_perf]]\n",
    "table = tabulate.tabulate(timing, tablefmt='html')\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "393059c36a3847c2d839809676c95267bdd3ca933a43346bb1db6dd5e60d130e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
